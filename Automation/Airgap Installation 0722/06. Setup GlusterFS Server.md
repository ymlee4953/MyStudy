# **06. Setup GlusterFS Server**

- Air-Gap Environment
- Get the installation files and package from the ansible/nexus server
- Target GlusterFS Cluster
  - 3 GlusterFS nodes 
  - 1 Hekti nodes : provide connection from K8s cluster to the Gluster Cluster

    | Server | Network | vCPU (core) | RAM (GB) | Internal Disk (GB) | external Disk (GB) |
    | :---: | :---: | :---: | :---: | :---: | :---: |
    | glusterfs-1 | Private Only | 2 | 4 | 25 | 300 |
    | glusterfs-2 | Private Only | 2 | 4 | 25 | 300 | 
    | glusterfs-3 | Private Only | 2 | 4 | 25 | 300 |
    | heketi-0 | Private Only | 2 | 4 | 25 | - | 

- GlusterFS Version : Latest  
---
## **Installation**


1. Prepare installation of Gluster File System for Air-Gap Environment
  
    1.1. Copy the nexus yum repository configuration file to each server

    - Copy Configuration file to each server (**glusterfs-1,2,3** and **heketi-0**)

          ansible-playbook -i k8s-cluster-hosts $HOME/ansible-playbooks/initialize/set_yum_repo_glusterfs.yml

2. Setup the GlusterFS Servers 

    2.1 Install glusterfs server

    - Install ***"glusterfs Server"*** at each glusterfs nodes (**glusterfs-1,2,3**)

          ansible-playbook -i k8s-cluster-hosts ~/ansible-playbooks/glusterfs/install_glusterfs_server.yml
    
    2.2 Start glusterfs server service

    - Start ***"glusterfs Server Service"*** at each glusterfs nodes (**glusterfs-1,2,3**)

          ansible-playbook -i k8s-cluster-hosts ~/ansible-playbooks/glusterfs/start-glusterfs.yml


    2.3 Set configuration for each glusterfs server

    - at glusterfs-1 nodes

          ssh ${GLUSTERFS_1}       
      
          for i in dm_snapshot dm_mirror dm_thin_pool; do
          modprobe $i
          done

          exit

    - at glusterfs-2 nodes

          ssh ${GLUSTERFS_2}       
      
          for i in dm_snapshot dm_mirror dm_thin_pool; do
          modprobe $i
          done

          exit

    - at glusterfs-3 nodes

          ssh ${GLUSTERFS_3}       
      
          for i in dm_snapshot dm_mirror dm_thin_pool; do
          modprobe $i
          done

          exit

    2.4 Set Peering beetween each glusterfs servers

    - Set peering glusterfs-1 node to glusterfs-2, 3 nodes

          ansible-playbook -i k8s-cluster-hosts ~/ansible-playbooks/glusterfs/gluster-peer-probe.yml

    - Check the peer Status  

          ssh ${GLUSTERFS_1}
          
          gluster peer status

          exit

      - Check Result :

            [root@glusterfs-1 ~]# gluster peer status
            Number of Peers: 2

            Hostname: glusterfs-2
            Uuid: bf30e0c4-bf2b-4089-9c1a-f4898cb9ba8d
            State: Peer in Cluster (Connected)

            Hostname: glusterfs-3
            Uuid: 116b7953-ce59-420c-8185-bd81f978d7e2
            State: Peer in Cluster (Connected)
            [root@glusterfs-1 ~]#




3. Setup Heketi Server 

    3.1 Install heketi-heketi-client.yml

    - Install heketi-client to heketi nodes

          ansible-playbook -i k8s-cluster-hosts ~/ansible-playbooks/glusterfs/install-heketi-heketi-client.yml

    3.2 Edit heketi.json file with new configuration

    - set the Heketi Password as the parameter 

          export HEKETI_PASSWORD=K8sadmin@ds

    - edit heketi.json file by replacing some parameters

          mkdir -p ~/ansible-playbooks/glusterfs
          
          cat <<EOF> ~/ansible-playbooks/glusterfs/edit_heketi_json.yml
          # edit_heketi_json.yml
          ---
          - hosts: HEKETI-0
            become: true
            tasks:
              - name: set password
                replace:
                  path: /etc/heketi/heketi.json
                  regexp: 'My Secret'
                  replace: "${HEKETI_PASSWORD}"
              - name: set executor to ssh
                replace:
                  path: /etc/heketi/heketi.json
                  regexp: '"executor": "mock"'
                  replace: '"executor": "ssh"'
              - name: set executor to ssh
                replace:
                  path: /etc/heketi/heketi.json
                  regexp: '"keyfile": "path/to/private_key"'
                  replace: '"keyfile": "/etc/heketi/heketi_key"'
              - name: set executor to ssh
                replace:
                  path: /etc/heketi/heketi.json
                  regexp: '"user": "sshuser"'
                  replace: '"user": "root"'
              - name: set executor to ssh
                replace:
                  path: /etc/heketi/heketi.json
                  regexp: "Optional: ssh port.  Default is 22"
                  replace: "22"
              - name: set executor to ssh
                replace:
                  path: /etc/heketi/heketi.json
                  regexp: "Optional: Specify fstab file on node.  Default is /etc/fstab"
                  replace: "/etc/fstab"
          EOF

          cat ~/ansible-playbooks/glusterfs/edit_heketi_json.yml

          ansible-playbook -i k8s-cluster-hosts ~/ansible-playbooks/glusterfs/edit_heketi_json.yml


    3.3 Set heketi server configuration

    - Login to at the heketi server

          ssh ${HEKETI_0}

    - Generate ssh-key to make automated login to each glusterfs servers

          ssh-keygen -f /etc/heketi/heketi_key -t rsa -N ''

          chown heketi:heketi /etc/heketi/heketi_key*
          
    - set the ssh login to glusterfs-1 

          ssh-copy-id -i /etc/heketi/heketi_key root@glusterfs-1

    - set the ssh login to glusterfs-2

          ssh-copy-id -i /etc/heketi/heketi_key root@glusterfs-2

    - set the ssh login to glusterfs-3

          ssh-copy-id -i /etc/heketi/heketi_key root@glusterfs-3

    - Start the heketi service and check the status of service

          systemctl start heketi
          systemctl status heketi

      - Check the Result: (Sample)

            [root@heteki-0 ~]# systemctl status heketi
            ● heketi.service - Heketi Server
              Loaded: loaded (/usr/lib/systemd/system/heketi.service; disabled; vendor preset: disabled)
              Active: active (running) since Sat 2021-07-24 06:04:50 CDT; 1s ago
            Main PID: 3243 (heketi)
              CGroup: /system.slice/heketi.service
                      └─3243 /usr/bin/heketi --config=/etc/heketi/heketi.json

            Jul 24 06:04:50 heteki-0.0.b.dev.k8s.ymlee systemd[1]: Started Heketi Server.
            Jul 24 06:04:50 heteki-0.0.b.dev.k8s.ymlee heketi[3243]: Heketi 9.0.0
            Jul 24 06:04:50 heteki-0.0.b.dev.k8s.ymlee heketi[3243]: [heketi] INFO 2021/07/24 06:04:50 Loaded ssh executor
            Jul 24 06:04:50 heteki-0.0.b.dev.k8s.ymlee heketi[3243]: [heketi] INFO 2021/07/24 06:04:50 Volumes per cluster limit is set to default value of 1000
            Jul 24 06:04:50 heteki-0.0.b.dev.k8s.ymlee heketi[3243]: [heketi] INFO 2021/07/24 06:04:50 GlusterFS Application Loaded
            Jul 24 06:04:50 heteki-0.0.b.dev.k8s.ymlee heketi[3243]: [heketi] INFO 2021/07/24 06:04:50 Started Node Health Cache Monitor
            Jul 24 06:04:50 heteki-0.0.b.dev.k8s.ymlee heketi[3243]: [heketi] INFO 2021/07/24 06:04:50 Started background pending operations cleaner
            Jul 24 06:04:50 heteki-0.0.b.dev.k8s.ymlee heketi[3243]: Listening on port 8080


    - See if the heketi working
         
          curl http://localhost:8080/hello

          exit

        - Check the result: 

              [root@heteki-0 ~]# curl http://localhost:8080/hello
              Hello from Heketi[root@heteki-0 ~]#


    - Copy the prepared heketi topology json file to heketi server
        
          ansible-playbook -i k8s-cluster-hosts ~/ansible-playbooks/glusterfs/copy_heketi_topology_json.yml

    3.4 Get the Heketi service information

    - Run at the heketi-0 server

          ssh ${HEKETI_0}

          heketi-cli topology info

          heketi-cli cluster list

          heketi-cli node list

          exit

      - Check the Result: (Sample)

            [root@heteki-0 ~]# heketi-cli topology info

            Cluster Id: 7704aec4675817708ce92d9e7be6eafe

                File:  true
                Block: true

                Volumes:


                Nodes:

                    Node Id: 18f015b8dfe2b70bac9d9d511f81da09
                    State: online
                    Cluster Id: 7704aec4675817708ce92d9e7be6eafe
                    Zone: 1
                    Management Hostnames: glusterfs-2
                    Storage Hostnames: 10.178.165.141
                    Devices:

                    Node Id: 46b3ceab6897c8e5140f57e94ace8915
                    State: online
                    Cluster Id: 7704aec4675817708ce92d9e7be6eafe
                    Zone: 1
                    Management Hostnames: glusterfs-1
                    Storage Hostnames: 10.178.165.155
                    Devices:

                    Node Id: 50c5d2fc14ddb94d016282dc0530e179
                    State: online
                    Cluster Id: 7704aec4675817708ce92d9e7be6eafe
                    Zone: 1
                    Management Hostnames: glusterfs-3
                    Storage Hostnames: 10.178.165.181
                    Devices:

            [root@heteki-0 ~]#
            [root@heteki-0 ~]# heketi-cli cluster list
            Clusters:
            Id:7704aec4675817708ce92d9e7be6eafe [file][block]
            [root@heteki-0 ~]#
            [root@heteki-0 ~]# heketi-cli node list
            Id:18f015b8dfe2b70bac9d9d511f81da09     Cluster:7704aec4675817708ce92d9e7be6eafe
            Id:46b3ceab6897c8e5140f57e94ace8915     Cluster:7704aec4675817708ce92d9e7be6eafe
            Id:50c5d2fc14ddb94d016282dc0530e179     Cluster:7704aec4675817708ce92d9e7be6eafe
            [root@heteki-0 ~]#

  - Set the parameters

    - get the heketi-cli cluster id from above

          export HEKETI_CLI_CLUSTER=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

    - make hash value for the heketi password
    
          echo -n ${HEKETI_PASSWORD} | base64

      - Check the Result: (Sample)

            [root@ansible-0 ~]# echo -n ${HEKETI_PASSWORD} | base64
            XXXXXXXXXXXXXXXX

    - get the heketi-secret from above

          export HEKETI_SECRET=XXXXXXXXXXXXXXXX

    3.5 Generate configurations for K8s Cluster

    - Generate gluster secret yaml

          cat <<EOF> ~/configurations/heketi/gluster-secret.yaml
          apiVersion: v1
          kind: Secret
          metadata:
            name: heketi-secret
            namespace: default
          type: "kubernetes.io/glusterfs"
          data:
            key: ${HEKETI_SECRET}
          EOF

          cat ~/configurations/heketi/gluster-secret.yaml

    - Generate gluster Storage Class yaml

          cat <<EOF> ~/configurations/heketi/glusterfs-sc.yaml
          apiVersion: storage.k8s.io/v1
          kind: StorageClass
          metadata:
            name: gluster-heketi
          provisioner: kubernetes.io/glusterfs
          reclaimPolicy: Delete
          volumeBindingMode: Immediate
          allowVolumeExpansion: true
          parameters:
            resturl: http://${HEKETI_0}:8080
            restuser: "admin"
            secretName: "heketi-secret"
            secretNamespace: "default"
            volumetype: "replicate:3"
            volumenameprefix: "k8s-dev"
            clusterid: "${HEKETI_CLI_CLUSTER}"
          EOF

          cat ~/configurations/heketi/glusterfs-sc.yaml

    - Generate gluster pvc yaml

          cat <<EOF> ~/configurations/heketi/gluster-pvc.yaml
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: gluster-pvc
            annotations:
              volume.beta.kubernetes.io/storage-class: gluster-heketi
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 1Gi
          EOF

          cat ~/configurations/heketi/gluster-pvc.yaml      
